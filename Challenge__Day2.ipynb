{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDwep1K8Erxl"
   },
   "source": [
    "**Project:** Data Minining Project for  X company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JzIu-UWIDXHw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7-ii3uyI8KY"
   },
   "source": [
    "The CRISP-DM Framework\n",
    "\n",
    "\n",
    "The CRISP-DM methodology provides a structured approach to planning a data mining project. It is a robust and well-proven methodology.\n",
    "* Business understanding (BU): Determine Business Objectives, Assess Situation, Determine Data Mining Goals, Produce Project Plan\n",
    "\n",
    "* Data understanding (DU): Collect Initial Data, Describe Data, Explore Data, Verify Data Quality\n",
    "\n",
    "* Data preparation (DP): Select Data, Clean Data, Construct Data, Integrate Data\n",
    "\n",
    "* Modeling (M): Select modeling technique, Generate Test Design, Build Model, Assess Model\n",
    "*  Evaluation (E): Evaluate Results, Review Process, Determine Next Steps\n",
    "*  Deployment (D): Plan Deployment, Plan Monitoring and Maintenance, Produce Final Report, Review Project\n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "[What is the CRISP-DM methodology?](https://www.sv-europe.com/crisp-dm-methodology/)\n",
    "\n",
    "[Introduction to CRISP DM Framework for Data Science and Machine Learning](https://www.linkedin.com/pulse/chapter-1-introduction-crisp-dm-framework-data-science-anshul-roy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lo7Ml7tMQOf"
   },
   "source": [
    "**Data Set**\n",
    "### The data is for company X which is trying to control attrition. \n",
    "### There are two sets of data: \"Existing employees\" and \"Employees who have left\". The following attributes are available for every employee.\n",
    "\n",
    "\n",
    "*   Satisfaction Level\n",
    "\n",
    "*   Last evaluation\n",
    "\n",
    "*   Number of projects\n",
    "\n",
    "*   Average monthly hours\n",
    "\n",
    "*   Time spent at the company\n",
    "*   Whether they have had a work accident\n",
    "\n",
    "\n",
    "*  Whether they have had a promotion in the last 5 years\n",
    "\n",
    "\n",
    "*   Departments (column sales)\n",
    "\n",
    "\n",
    "*   Salary\n",
    "\n",
    "\n",
    "*  Whether the employee has left\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjSj2A2sSph_"
   },
   "source": [
    "**Your Role**\n",
    " \n",
    "\n",
    "*   As data science team member X company asked you to answer this two questions.\n",
    "*  What type of employees is leaving? \n",
    "\n",
    "*   Determine which employees are prone to leave next.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajdEVA7LiBUp"
   },
   "source": [
    "Business Understanding\n",
    "\n",
    "---\n",
    "\n",
    "This step mostly focuses on understanding the Business in all the different aspects. It follows the below different steps.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Identify the goal and frame the business problem.\n",
    "* Prepare Analytical Goal i.e. what type of performance metric and loss function to use\n",
    "* Gather information on resource, constraints, assumptions, risks etc\n",
    "* Gather information on resource, constraints, assumptions, risks etc\n",
    "*   Prepare Work Flow Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4MwiCYzj2_u"
   },
   "source": [
    "### Write the main objectives of this project in your words?\n",
    "minimum of 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "STyLda45j1Mf"
   },
   "outputs": [],
   "source": [
    "main_objectives ='''This project aims to mine the data of company X which is trying to control attrition\n",
    "by understanding what type of employee is leaving and also determine which employees are prone to leave next\n",
    "making use of the CRISP-DM Framework '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CuOlxLxKMOLI"
   },
   "outputs": [],
   "source": [
    "assert len(main_objectives) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(main_objectives) > 80 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyXeNxlCkbaw"
   },
   "source": [
    "### Outline the different data analysis steps you will follow to carry out the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rC-tl8sUksQq"
   },
   "outputs": [],
   "source": [
    "dm_outline = '''1. Understanding definition of each attributes of both datasets \n",
    "2. Analysing the descriptive statistics of datasets, size, datatypes etc.\n",
    "3. Handling missing values if found any in datasets\n",
    "4. Plotting univariate and multivariate analysis charts to understand relationships between attributes\n",
    "5. Checking if the satisfaction level column of employees is balnced\n",
    "6. Plotting the relationship between employees' time spent at the company and Whether they have had a promotion \n",
    "   in the last 5 years and so on with other variables.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-K1mWuDoksTk"
   },
   "outputs": [],
   "source": [
    "assert len(dm_outline) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(dm_outline) > 70 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmUDFG1wkzUy"
   },
   "source": [
    "### What metrics will you use to measure the performance of your data analysis model? \n",
    "Write the equations of the metrics here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCNulojKk_BP"
   },
   "source": [
    "F1score \n",
    "\n",
    "Precision = $\\frac{TP}{(TP + FP)}$\n",
    "\n",
    "Recall = $\\frac{TP}{(TP + FN)}$\n",
    "\n",
    "F1 = 1/((1/Precision) + (1/Recall))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLS2YHoRk_EK"
   },
   "source": [
    "Why do you choose these metrics? minimum of 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LSynT14KlPSJ"
   },
   "outputs": [],
   "source": [
    "why_metrics = '''F1 Score is the Harmonic Mean between precision and recall which tells\n",
    "how precise the model is (how many instances itclassifies correctly), as well as how robust it is (it does not \n",
    "miss a significant number of instances).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yr-Mk0E8lPVJ"
   },
   "outputs": [],
   "source": [
    "assert len(why_metrics) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(why_metrics) > 80 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAo19Ip6lUtm"
   },
   "source": [
    "### How would you know if your data analysis work is a success or not?\n",
    "minimum of 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HESsiXW5llX-"
   },
   "outputs": [],
   "source": [
    "how_success = '''1. When the data is being summarized and understood by stakeholders\n",
    "2. The model fits well on unseen data to solve company X problem\n",
    "3. Stakeholders accept the result of the presentation '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FdUoiMIOlmXq"
   },
   "outputs": [],
   "source": [
    "assert len(how_success) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(how_success) > 80 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQE6dqo6l1TZ"
   },
   "source": [
    "## What kind of challenges do you expect in your analysis?\n",
    "List at least 3 challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WrAhBQhQl8Lh"
   },
   "outputs": [],
   "source": [
    "challenge_text = '''1. Lack of support from the company to provide useful informations when asked\n",
    "2. Small attributes of data\n",
    "3. Imabalanced data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EedHa-Pll8X7"
   },
   "outputs": [],
   "source": [
    "assert len(challenge_text) > 100 \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(how_success) > 80 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcJ8M6uWDeSE"
   },
   "source": [
    "<h2>Using the processed twitter data from yesterday's challenge</h2>.\n",
    "\n",
    "\n",
    "- Form a new data frame (named `cleanTweet`), containing columns $\\textbf{clean-text}$ and $\\textbf{polarity}$.\n",
    "\n",
    "- Write a function `text_category` that takes a value `p` and returns, depending on the value of p, a string `'positive'`, `'negative'` or `'neutral'`.\n",
    "\n",
    "- Apply this function (`text_category`) on the $\\textbf{polarity}$ column of `cleanTweet` in 1 above to form a new column called $\\textbf{score}$ in `cleanTweet`.\n",
    "\n",
    "- Visualize The $\\textbf{score}$ column using piechart and barchart\n",
    "\n",
    "<h5>Now we want to build a classification model on the clean tweet following the steps below:</h5>\n",
    "\n",
    "* Remove rows from `cleanTweet` where $\\textbf{polarity}$ $= 0$ (i.e where $\\textbf{score}$ = Neutral) and reset the frame index.\n",
    "* Construct a column $\\textbf{scoremap}$ Use the mapping {'positive':1, 'negative':0} on the $\\textbf{score}$ column\n",
    "* Create feature and target variables `(X,y)` from $\\textbf{clean-text}$ and $\\textbf{scoremap}$ columns respectively.\n",
    "* Use `train_test_split` function to construct `(X_train, y_train)` and `(X_test, y_test)` from `(X,y)`\n",
    "\n",
    "* Build an `SGDClassifier` model from the vectorize train text data. Use `CountVectorizer()` with a $\\textit{trigram}$ parameter.\n",
    "\n",
    "* Evaluate your model on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "85WxmGNGDcBY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.read_csv('cleaned_fintech_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>original_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>lang</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>...</th>\n",
       "      <th>original_author</th>\n",
       "      <th>screen_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>place</th>\n",
       "      <th>place_coord_boundaries</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Thu Jun 17 06:26:34 +0000 2021</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>Giving forth life is becoming a burden in Keny...</td>\n",
       "      <td>Giving forth life becoming burden Kenya This m...</td>\n",
       "      <td>Sentiment(polarity=0.3194444444444445, subject...</td>\n",
       "      <td>0.3194444444444445</td>\n",
       "      <td>0.5305555555555556</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>reen_law</td>\n",
       "      <td>398</td>\n",
       "      <td>70</td>\n",
       "      <td>223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>janetmachuka_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-06-17 06:26:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Thu Jun 17 06:26:37 +0000 2021</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Teenmaar - 26cr\\nPanja - 32.5cr\\nGabbarsingh -...</td>\n",
       "      <td>Teenmaar crPanja crGabbarsingh cr Khaleja Kuda...</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>in</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Amigo9999_</td>\n",
       "      <td>19047</td>\n",
       "      <td>132</td>\n",
       "      <td>1084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maheshblood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India</td>\n",
       "      <td>2021-06-17 06:26:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Thu Jun 17 06:26:42 +0000 2021</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Rei chintu 2013 lo Vachina Ad Nizam ne 2018 lo...</td>\n",
       "      <td>Rei chintu lo Vachina Ad Nizam ne lo kottaru f...</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hi</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>MallaSuhaas</td>\n",
       "      <td>47341</td>\n",
       "      <td>2696</td>\n",
       "      <td>2525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hail_Kalyan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vizag</td>\n",
       "      <td>2021-06-17 06:26:42+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Thu Jun 17 06:26:44 +0000 2021</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Today is World Day to Combat #Desertification ...</td>\n",
       "      <td>Today World Day Combat Restoring degraded land...</td>\n",
       "      <td>Sentiment(polarity=0.25, subjectivity=0.65)</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.65</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>CIACOceania</td>\n",
       "      <td>7039</td>\n",
       "      <td>343</td>\n",
       "      <td>387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Desertification, Drought, resilience</td>\n",
       "      <td>EdwardVrkic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>2021-06-17 06:26:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Thu Jun 17 06:26:47 +0000 2021</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Hearing #GregHunt say he's confident vaccines ...</td>\n",
       "      <td>Hearing say 's confident vaccines delivered li...</td>\n",
       "      <td>Sentiment(polarity=0.5, subjectivity=0.8333333...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8333333333333334</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>MccarronWendy</td>\n",
       "      <td>26064</td>\n",
       "      <td>419</td>\n",
       "      <td>878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GregHunt, Morrison</td>\n",
       "      <td>WriteWithDave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sydney, New South Wales</td>\n",
       "      <td>2021-06-17 06:26:47+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      created_at  \\\n",
       "0         0.0  Thu Jun 17 06:26:34 +0000 2021   \n",
       "1         1.0  Thu Jun 17 06:26:37 +0000 2021   \n",
       "2         2.0  Thu Jun 17 06:26:42 +0000 2021   \n",
       "3         3.0  Thu Jun 17 06:26:44 +0000 2021   \n",
       "4         4.0  Thu Jun 17 06:26:47 +0000 2021   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "1  <a href=\"http://twitter.com/download/android\" ...   \n",
       "2  <a href=\"http://twitter.com/download/android\" ...   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "4  <a href=\"http://twitter.com/download/android\" ...   \n",
       "\n",
       "                                       original_text  \\\n",
       "0  Giving forth life is becoming a burden in Keny...   \n",
       "1  Teenmaar - 26cr\\nPanja - 32.5cr\\nGabbarsingh -...   \n",
       "2  Rei chintu 2013 lo Vachina Ad Nizam ne 2018 lo...   \n",
       "3  Today is World Day to Combat #Desertification ...   \n",
       "4  Hearing #GregHunt say he's confident vaccines ...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  Giving forth life becoming burden Kenya This m...   \n",
       "1  Teenmaar crPanja crGabbarsingh cr Khaleja Kuda...   \n",
       "2  Rei chintu lo Vachina Ad Nizam ne lo kottaru f...   \n",
       "3  Today World Day Combat Restoring degraded land...   \n",
       "4  Hearing say 's confident vaccines delivered li...   \n",
       "\n",
       "                                           sentiment            polarity  \\\n",
       "0  Sentiment(polarity=0.3194444444444445, subject...  0.3194444444444445   \n",
       "1          Sentiment(polarity=0.0, subjectivity=0.0)                 0.0   \n",
       "2          Sentiment(polarity=0.0, subjectivity=0.0)                 0.0   \n",
       "3        Sentiment(polarity=0.25, subjectivity=0.65)                0.25   \n",
       "4  Sentiment(polarity=0.5, subjectivity=0.8333333...                 0.5   \n",
       "\n",
       "         subjectivity lang favorite_count  ... original_author screen_count  \\\n",
       "0  0.5305555555555556   en              0  ...        reen_law          398   \n",
       "1                 0.0   in              0  ...      Amigo9999_        19047   \n",
       "2                 0.0   hi              0  ...     MallaSuhaas        47341   \n",
       "3                0.65   en              0  ...     CIACOceania         7039   \n",
       "4  0.8333333333333334   en              0  ...   MccarronWendy        26064   \n",
       "\n",
       "  followers_count friends_count possibly_sensitive  \\\n",
       "0              70           223                NaN   \n",
       "1             132          1084                NaN   \n",
       "2            2696          2525                NaN   \n",
       "3             343           387                NaN   \n",
       "4             419           878                NaN   \n",
       "\n",
       "                               hashtags  user_mentions place  \\\n",
       "0                                   NaN  janetmachuka_   NaN   \n",
       "1                                   NaN    maheshblood   NaN   \n",
       "2                                   NaN    Hail_Kalyan   NaN   \n",
       "3  Desertification, Drought, resilience    EdwardVrkic   NaN   \n",
       "4                    GregHunt, Morrison  WriteWithDave   NaN   \n",
       "\n",
       "    place_coord_boundaries                  timestamp  \n",
       "0                      NaN  2021-06-17 06:26:34+00:00  \n",
       "1                    India  2021-06-17 06:26:37+00:00  \n",
       "2                    Vizag  2021-06-17 06:26:42+00:00  \n",
       "3         Papua New Guinea  2021-06-17 06:26:44+00:00  \n",
       "4  Sydney, New South Wales  2021-06-17 06:26:47+00:00  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanTweet = pd.DataFrame(twitter_df, columns = ['clean-text', 'polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from wordcloud import STOPWORDS,WordCloud\n",
    "#from gensim import corpora\n",
    "from textblob import TextBlob\n",
    "import sys\n",
    "import tweepy\n",
    "import statistics\n",
    "import string\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-18-28378666c976>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-28378666c976>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    keyword = input(“Please enter keyword or hashtag to search: “)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "def text_category(p):\n",
    "    return p\n",
    "\n",
    "keyword = input(“Please enter keyword or hashtag to search: “)\n",
    "noOfTweet = int(input (“Please enter how many tweets to analyze: “))\n",
    "tweets = tweepy.Cursor(api.search, q=keyword).items(noOfTweet)\n",
    "positive = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "polarity = 0\n",
    "tweet_list = []\n",
    "neutral_list = []\n",
    "negative_list = []\n",
    "positive_list = []\n",
    "for tweet in tweets:\n",
    "    tweet_list.append(tweet.text)\n",
    "    analysis = TextBlob(tweet.text)\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(tweet.text)\n",
    "    pos = score[‘positive’]\n",
    "    neg = score[‘negative’]\n",
    "    neu = score[‘neutral’]\n",
    "    polarity += analysis.sentiment.polarit \n",
    "        \n",
    "    if neg > positive:\n",
    "        negative_list.append(tweet.text)\n",
    "        negative_list.append(tweet.text)\n",
    "        negative += 1\n",
    "    elif pos > negative:\n",
    "        positive_list.append(tweet.text)\n",
    "        positive += 1\n",
    " \n",
    "    elif positive == negative:\n",
    "        neutral_list.append(tweet.text)\n",
    "        neutral += 1\n",
    "positive = percentage(positive, noOfTweet)\n",
    "negative = percentage(negative, noOfTweet)\n",
    "neutral = percentage(neutral, noOfTweet)\n",
    "polarity = percentage(polarity, noOfTweet)\n",
    "positive = format(positive, ‘.1f’)\n",
    "negative = format(negative, ‘.1f’)\n",
    "neutral = format(neutral, ‘.1f’)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Challenge_ Day2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
